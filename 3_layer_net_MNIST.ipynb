{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46bf8b2e-c456-4b56-a4a7-81f05398203b",
   "metadata": {},
   "source": [
    "# 3 LAYER NET."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65af43-cac4-4345-8ced-90b9dd1ee0a7",
   "metadata": {},
   "source": [
    "BROKEN AI\n",
    "3 layer per allenamento con MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c498c-7d84-49c4-848d-5d84104de8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "# split dataset into training and test set\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train1=x_train\n",
    "y_train1=y_train\n",
    "x_test1=x_test\n",
    "y_test1=y_test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb130ce9-8a5e-42a4-9eda-005099531633",
   "metadata": {},
   "source": [
    "\n",
    "plt.imshow(x_train[66], cmap=plt.cm.binary)\n",
    "print(y_train[66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee228411-4de3-43d8-b665-a88f40332f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21359b75-fe80-4787-a4ba-a782f976881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8750ee4-1b0c-4242-9d08-99c2855de176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967a584-f8db-4fc1-b4d2-4e03145dc5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b83945c-2c42-48f6-a246-31a976bfb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33737199-cfcc-432f-b61f-d7c1e4b1a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553184ea-843e-4761-8567-b9f92f914973",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",#oppure adam per avere learning rate adattivo\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9aecc631-aeac-44d3-8455-eecd909f3d02",
   "metadata": {},
   "source": [
    "per salvare in caso di miglioramenti accuracy con fit\n",
    "\n",
    "\n",
    "'''\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "history=model.fit(x_train, y_train, epochs=3, validation_split=0.2, callbacks=[checkpoint])\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2b4fc57-9dc2-4f5e-8379-3aea60b5ff3c",
   "metadata": {},
   "source": [
    "fit con uso di tensorboard\n",
    "\n",
    "'''\n",
    "import datetime\n",
    "%load_ext tensorboard\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs')\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32478e-a0af-4080-a6f0-2f12627b0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping \n",
    "keras_callbacks = ReduceLROnPlateau(\n",
    "    monitor= 'val_loss',     # Metrica da monitorare (qui è la loss di validazione) \n",
    "    factor=0.95,             # Riduci il learning rate: Moltiplicatore per ridurre il learning rate (nuovo_lr = lr * factor)\n",
    "    patience=1,             # Aspetta 1 epoche senza miglioramenti prima di ridurre LR\n",
    "    verbose=1,              # Mostra un messaggio quando il learning rate viene ridotto\n",
    "    min_lr=0,             # Learning rate minimo\n",
    "    min_delta=0.05      # min_delta=quantità minima di miglioramento richiesta per considerare il valore della perdita come un miglioramento\n",
    ")\n",
    "\n",
    "\n",
    "#per modificare epochs e batch_size modificare rispettivamente 'e' e 'b' (verranno modificati anche nella cnn)\n",
    "e=30\n",
    "b=700\n",
    "\n",
    "\n",
    "\n",
    "#altro callbacks con Earlystopping\n",
    "keras_callbacks1 = [EarlyStopping(monitor='val_loss', patience=6, verbose=1, min_delta=0.001)]\n",
    "#min_delta=quantità minima di miglioramento richiesta per considerare il valore della perdita come un miglioramento\n",
    "\n",
    "\n",
    "start_time = time.time() #registra tempo di inizio\n",
    "history = model.fit(x_train, y_train, epochs=e, batch_size=b, verbose=1,\n",
    "                    validation_split=0.2, callbacks=[keras_callbacks,keras_callbacks1])\n",
    "\n",
    "end_time = time.time() ##registra tempo di fine\n",
    "\n",
    "\n",
    "#model.fit(x_train, y_train, batch_size=60000, epochs=100,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea71cf-e33b-4ef5-b3db-ddd447416d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', round(test_acc,4))\n",
    "print('Test loss:', round(test_loss,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cddf4e-5f2e-47ce-b59e-0add0c6cf499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=30)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual class')\n",
    "    plt.xlabel('Predicted class')\n",
    "   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce68fc-a521-487a-92f8-1a8058478f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(x_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred, axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test, axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b97bef-4cf6-4f9a-96fa-f19e14368b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss-rate\n",
    "val_losses=history.history[\"val_loss\"]\n",
    "train_losses=history.history[\"loss\"]\n",
    "\n",
    "epochs = range(1, len(val_losses) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Training loss\")\n",
    "plt.plot(epochs,val_losses,c=\"red\",label=\"Validation\")\n",
    "plt.plot(epochs,train_losses,c=\"orange\",label=\"Training\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cross entropy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss_ANN.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aaadee-ff93-43aa-b6c5-d94505c8baae",
   "metadata": {},
   "source": [
    "# rete modello (CNN)\n",
    "implemento una rete modello perfettamente funzionante (tale cnn con 8 layer è più stabile e meglio ottimizzata, ottima accuracy e loss basso).\n",
    "tale modello può essere utile per un eventuale confronto dei dati in output della rete ANN con un set di dati che simuli 'le risposte di un paziente perfettamente sano'\n",
    "NOTA:per quanto ottima la CNN non è perfetta potrà sbagliare qualche test, quindi questo introduce un certo margine di errore per la rete ANN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5846b3-be99-45ea-9d2f-df2ed851890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPooling2D\n",
    "\n",
    "x_train_cnn=x_train1.reshape(x_train1.shape[0],x_train1.shape[1],x_train1.shape[2],1)\n",
    "x_test_cnn=x_test1.reshape(x_test1.shape[0],x_test1.shape[1],x_test1.shape[2],1)\n",
    "\n",
    "y_train_cat=to_categorical(y_train1)\n",
    "\n",
    "    # definiamo il modello in maniera funzionale\n",
    "cnn= Sequential()\n",
    "cnn.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "cnn.add(MaxPooling2D(strides=2))\n",
    "cnn.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "cnn.add(MaxPooling2D(strides=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "cnn.add(Dense(84, activation='relu'))\n",
    "cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # definizione dell'ottimizzatore\n",
    "    #opt=Adam(learning_rate=1e-3) #algoritmo di ottimizzazione, learning rate indica il tasso di apprendimento\n",
    "\n",
    "    # compiliamo il modello prima dell'addestramento\n",
    "cnn.compile(optimizer=\"adam\",\n",
    "                       loss='categorical_crossentropy', #loss function\n",
    "                       metrics=['accuracy'])\n",
    "keras_callbacks = [\n",
    "EarlyStopping(monitor='val_loss', patience=5, verbose=1, min_delta=0.001)#quantità minima di miglioramento richiesta per considerare il valore della perdita come un miglioramento\n",
    "]\n",
    "start_time = time.time() #registra tempo di inizio\n",
    "history = cnn.fit(x_train_cnn, y_train_cat, epochs=e, batch_size=b, verbose=1,\n",
    "                    validation_split=0.2, callbacks=keras_callbacks)\n",
    "    \n",
    "   \n",
    "\n",
    "end_time = time.time() ##registra tempo di fine\n",
    "    \n",
    "cnn_predictions = cnn.predict(x_test1)\n",
    "y_test_cnn = to_categorical(y_test1, num_classes=10)\n",
    "\n",
    "test_loss_R, test_acc_R = cnn.evaluate(x_test_cnn, y_test_cnn)\n",
    "print('Test accuracy cnn:', round(test_acc_R,4))\n",
    "print('Test loss cnn:', round(test_loss_R,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0af03-6a59-43d0-8772-d967ccd7ef87",
   "metadata": {},
   "source": [
    "# simulazione \n",
    "comportamento di un paziente (non bravo) a cui vengono proposte immagini da classificare (MNIST) e confronto con un paziente perfettamente sano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c5375-fb21-44da-8471-46036bd6a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29d40d8-5f82-43c2-8f70-013c590a6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b=\"si\"\n",
    "while b==\"si\":\n",
    "    a=input(\"quale immagine vuoi che legga? fornire un numero da 0 a 10.000:\")\n",
    "    \n",
    "    print(\"io ho interpretato l'immagine numero {} come: {}\".format(a,np.argmax(predictions[int(a)])))\n",
    "    print(\"\\necco la predizione che mi ha permesso di fare questa scelta:\\n\\n\",predictions[int(a)])\n",
    "    #print(np.sum(predictions[int(a)]))\n",
    "    print(\"\\nla risposta corretta è:\",y_test1[int(a)])\n",
    "    print(\"\\n il paziente modello avrebbe risposto: {}\\n\".format(np.argmax(cnn_predictions[int(a)])))\n",
    "    print(\"\\nvuoi che mostri l'immagine selezionata?\\n\") \n",
    "    if input()=='si':\n",
    "        plt.imshow(x_test1[int(a)], cmap=plt.cm.binary)\n",
    "        plt.show()\n",
    "    \n",
    "    for i in range(9999):\n",
    "        predictions[int(i)]=np.argmax(predictions[int(i)])\n",
    "        cnn_predictions[int(i)]=np.argmax(cnn_predictions[int(i)])\n",
    "        \n",
    "    #print( predictions)\n",
    "    uguali =np.sum(np.array(cnn_predictions) == np.array(predictions))\n",
    "    percentuale = (uguali / cnn_predictions.size) * 100\n",
    "\n",
    "    print(\"I due pazienti hanno fornito un numero di risposte uguali pari a: {},\\n il 'paziente in esame' ha fornito il {:.2f}% delle risposte che il paziente modello ha fornito.\".format(uguali, percentuale))\n",
    "\n",
    "    b=input(\"\\nvuoi che legga un'altra immagine?\\n\")\n",
    "    \n",
    "print(\"se non è 'si' per me è no ;), alla prossima!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d9206-414a-43d9-b861-62d351d7d9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7efbeb-66da-494b-9c11-c1ee327dbfaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ae5e2-a93a-46f0-9bbc-99dd207ece4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770631e-85c1-4840-aa0e-a9cdea993443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c397e1-256c-4282-9985-f75b223b398a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b218d10-37ae-4cab-b76b-3dd6cdc4d74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e174d0f-b39b-4634-96f3-87771e7c4883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
